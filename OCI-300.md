# OCI Workshop: Deploy a simple web app with Terraform and Oracle Resource Mananger

Updated: October 25th, 2019

The Oracle Cloud Infrastructure Resource Manager is a fully managed service that lets you
provision infrastructure resources on Oracle Cloud Infrastructure using Terraform. You can bring in your Terraform template denition and easily create and manage your infrastructure resources. This allows you to use infrastructure-as-code to automate provisioning across all OCI resources including Compute, Networking, Load Balancers, Block and Object Storage.

Resource Manager also integrates with Identity and Access Management (IAM) so you can define granular permissions for Terraform operations. It currently has support for CLI, SDK and Console.


## Objectives
- Configure IAM to control user access in Resource Manager
- Create Resource Mananger Stack
- Execute Jobs: Plan, Apply, and Destroy. 

### **STEP 1**: Configure IAM to control user access in Resource Manager
**Note**: You can skip the steps below if you are using an user with admin privileges. If this were a real production system, it’s both more secure and practical to create additional groups with more granular permissions. For example, it is likely we’d need to create a development team group that can only use predened stacks and run jobs against it (use-orm-stack and use-orm-job, respectively). 

STOPPED HERE^^^

- Click the **hamburger icon** in the upper left corner to open the navigation menu. Under the **Compute** section of the menu, click **Instances**.

  ![](images/100ODA/instances.png)
  
- Click on **Create Instance Configuration**

  ![](images/100ODA/instanceConfig.png)
  
### **STEP 2**: Create an Instance Pool

- On the instance configuration page select the configuration we created in the previous step. On the resulting page click on create instance pool.

  ![](images/100ODA/instancePool.png)
  
- Select the compartment, and provide a suitable name for the instance pool. Increase the number of instances to 5.
In the AD selection, select AD1, and select the same compartment for both VCN and subnet and select the corresponding VCN (AutoscaleVCN) and Subnet (name ending with AD-1). Click create instance pool.

  ![](images/100ODA/cInstancePool.png)
 
- The instances will be provisioned and it might take a few minutes. 

### **STEP 2**: Create an Autoscaling Configuration

- Once the instances in the instance pool are up and running, click on actions → Create Autoscaling Configuration on the instance pool page.

  ![](images/100ODA/autoConfig.png)
  
- Select the right compartment and provide a suitable name.
- Select the instance pool we created in the previous step and keep cooldown time as default. 
- In the Autoscaling policy section, provide a suitable name and choose CPU utilization as the performance metric.
  
  ![](images/100ODA/autoConfig2.png)
  
- In the following section on scaling rules, add the following rules and then click create.

  Scale-out parameter → Greater than (>)
  
  Threshold percentage → 30
  
  Number of Instances to Add → 1
  
  Scale-in parameter → Less than (<)
  
  Threshold percentage → 20
  
  Number of Instances to Remove → 1

  ![](images/100ODA/scalingRule.png)

- The instance pool will now scale down to the minimum number of instances set in the autoscaling configuration.

### **STEP 3**: Induc CPU Stress on the Instance to Demonstrate Autoscaling
- Copy the **Public IP address** of the compute instance running in your instance pool 
  ![](images/100ODA/publicIP.png)
  
- To connect to the instance, you can use  Terminal if you are using MAC or  Gitbash if you are
using Windows. On your terminal or gitbash enter the following command:

`
  ssh opc@<public_ip_address>
`
  
- If you have a different path for your SSH key enter the following:

`
  ssh -i <path_to_private_ssh_key> opc@<public_ip_address>
`
  ![](images/100ODA/login.png)
  
- Run the following linux commands:

`
  sudo su
  yum install stress
  stress --cpu 2 --timeout 300s
`

  ![](images/100ODA/stress.png)

- These commands will increase CPU utilization of Linux instance for a time of 5 mins which is enough time for OCI to detect that CPU utilization is above threshold and thus will start autoscaling to add 1 instance in the instance pool. Following another inactive period of monitoring, OCI will remove the added instance based on scale down configuration.

  

**This completes the OCI Workshop!**
